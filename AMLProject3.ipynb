{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwASOOm2Ats-"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import csv\n",
        "import math\n",
        "import copy\n",
        "import time\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from numpy import *\n",
        "import pandas as pd\n",
        "from random import shuffle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature = []"
      ],
      "metadata": {
        "id": "LpysieEIAywI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(matrix):\n",
        "  a = np.array(matrix)\n",
        "  a = a.astype(float)\n",
        "  normalized_matrix = (a - a.min(axis = 0)) / (a.max(axis = 0) - a.min(axis = 0))\n",
        "  return normalized_matrix"
      ],
      "metadata": {
        "id": "pf5yBfSgAz_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_csv(file):\n",
        "  df = pd.read_csv(file)\n",
        "  dataframe = df.to_numpy()\n",
        "  return dataframe"
      ],
      "metadata": {
        "id": "8nORWez5FW5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_numpy_array(arr):\n",
        "  np.random.shuffle(arr)\n",
        "  return arr"
      ],
      "metadata": {
        "id": "ozxJ0h_cHPES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def entropy(y):\n",
        "    class_frequency = {}\n",
        "    attribute_entropy = 0\n",
        "\n",
        "    for i in y:\n",
        "        if i in class_frequency:\n",
        "            class_frequency[i]+=1\n",
        "        else:\n",
        "            class_frequency[i] = 1\n",
        "\n",
        "    for x in class_frequency.values():\n",
        "        p1= -x/float(len(y))\n",
        "        p2= math.log(x/float(len(y)),2)\n",
        "        attribute_entropy +=  p1*p2 \n",
        "\n",
        "    return attribute_entropy"
      ],
      "metadata": {
        "id": "gKcwyDyGKO61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_set(X):\n",
        "  Y = X[:,-1]\n",
        "  Y = Y.reshape(len(Y),1)\n",
        "  normalized_new_X = normalize(X[:,:-1])\n",
        "  X = np.concatenate((normalized_new_X,Y),axis=1)\n",
        "  rows= X.shape[0]\n",
        "  testing_set = round(rows * 0.1)\n",
        "\n",
        "  start = 0\n",
        "  end = testing_set\n",
        "\n",
        "  testing_features = []\n",
        "  testing_labels = []\n",
        "  training_features = []\n",
        "  training_labels = []\n",
        "\n",
        "  for i in range(10):\n",
        "    test_set = X[start:end,:]\n",
        "    train_beforetest = X[:start,:]\n",
        "    train_aftertest = X[end:,:]\n",
        "    train_set = np.concatenate((train_beforetest,train_aftertest),axis=0)\n",
        "    testing_set_labels = test_set[:,-1]\n",
        "    testing_set_labels.flatten()\n",
        "    train_set_labels = train_set[:,-1]\n",
        "    train_set_labels.flatten()\n",
        "    test_set = test_set[:,:-1].astype(np.float)\n",
        "    train_set = train_set[:,:-1].astype(np.float)\n",
        "    testing_features.append(test_set)\n",
        "    testing_labels.append(testing_set_labels)\n",
        "    training_features.append(train_set)\n",
        "    training_labels.append(train_set_labels)\n",
        "    start = end\n",
        "    end = end + testing_set\n",
        "\n",
        "  return training_features, training_labels, testing_features, testing_labels"
      ],
      "metadata": {
        "id": "74xlr52oG1oY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Node(object):\n",
        "  def __init__(self, val, lchild, rchild,thea,leaf):\n",
        "    self.root_value = val\n",
        "    self.root_left = lchild\n",
        "    self.root_right = rchild\n",
        "    self.theta = thea\n",
        "    self.leaf = leaf\n",
        "\n",
        "  def is_leaf(self):\n",
        "    return self.leaf\n",
        "\n",
        "  def ret_thetha(self):\n",
        "    return self.theta\n",
        "\n",
        "  def ret_root_value(self):\n",
        "    return self.root_value\n",
        "\n",
        "  def ret_llist(self):\n",
        "    return self.root_left\n",
        "\n",
        "  def ret_rlist(self):\n",
        "    return self.root_right\n",
        "\n",
        "  def __repr__(self):\n",
        "    return \"(%r, %r, %r, %r)\" %(self.root_value,self.root_left,self.root_right,self.theta)"
      ],
      "metadata": {
        "id": "yE679-_wNZtZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecisionTree(object):\n",
        "  fea_list = []\n",
        "\n",
        "  def __init__(self):\n",
        "    self.root_node = None\n",
        "\n",
        "  def cal_major_class_values(self,class_values):\n",
        "    return Counter(class_values).most_common(1)[0][0]\n",
        "\n",
        "  def cal_best_theta_value(self,ke,attri_list):\n",
        "    data_list = []\n",
        "    class_labels= []\n",
        "\n",
        "    for i in attri_list:\n",
        "      data_list.append(i[0])\n",
        "      class_labels.append(i[1])\n",
        "    entropy_result = entropy(class_labels)\n",
        "    max_info_gain = 0\n",
        "    theta=0\n",
        "\n",
        "    best_index_left = []\n",
        "    best_index_right = []\n",
        "    class_labels_AS = []\n",
        "    data_list.sort()\n",
        "\n",
        "    for i in range(len(data_list)-1):\n",
        "      current_theta = float(data_list[i]+data_list[i+1])/2\n",
        "\n",
        "      index_less_than = []\n",
        "      value_less_than = []\n",
        "      index_greater_than = []\n",
        "      value_greater_than =[]\n",
        "      counter = 0\n",
        "\n",
        "      for c,j in enumerate(attri_list):\n",
        "        if (j[0]<=current_theta):\n",
        "          index_less_than.append(c)\n",
        "          value_less_than.append(j[1])\n",
        "        else:\n",
        "          index_greater_than.append(c)\n",
        "          value_greater_than.append(j[1]) \n",
        "      entropy_less= entropy(value_less_than)\n",
        "      entropy_great= entropy(value_greater_than)\n",
        "      info_gain= (len(index_less_than)/len(class_labels)) * entropy_less + ((len(index_greater_than)/len(class_labels))*entropy_great)\n",
        "      info_gain = entropy_result -info_gain\n",
        "\n",
        "      if info_gain> max_info_gain:\n",
        "        max_info_gain=info_gain\n",
        "        theta= current_theta\n",
        "        best_index_right=index_greater_than\n",
        "        best_index_left=index_less_than\n",
        "        class_labels_AS= value_greater_than+value_less_than\n",
        "\n",
        "    return max_info_gain, theta, best_index_left, best_index_right, class_labels_AS\n",
        "\n",
        "  def best_feature(self,dict_rep):\n",
        "    key_value=None\n",
        "\n",
        "    best_info_gain=-1\n",
        "    best_theta=0\n",
        "    best_left_list=[]\n",
        "    best_right_rist=[]\n",
        "    best_class_labels_AS=[]\n",
        "    result_list=[]\n",
        "\n",
        "    for ke in dict_rep.keys():\n",
        "      max_info_gain, theta, best_index_left,best_index_right, class_labels_AS= self.cal_best_theta_value(ke, dict_rep[ke])\n",
        "            \n",
        "      if max_info_gain> best_info_gain:\n",
        "        best_info_gain=max_info_gain\n",
        "        best_theta=theta\n",
        "        key_value= ke\n",
        "        best_left_list=best_index_left\n",
        "        best_right_rist=best_index_right\n",
        "        best_class_labels_AS= class_labels_AS\n",
        "    result_list.append(key_value)\n",
        "    result_list.append(best_theta)\n",
        "    result_list.append(best_left_list)\n",
        "    result_list.append(best_right_rist)\n",
        "    result_list.append(best_class_labels_AS)\n",
        "    return result_list\n",
        "\n",
        "  def get_remainder_dict(self,dict_of_everything,index_split):\n",
        "    global fea_list\n",
        "    split_dict={}\n",
        "    for ke in dict_of_everything.keys():\n",
        "      value_list=[]\n",
        "      modified_list=[]\n",
        "      key_values= dict_of_everything[ke]\n",
        "      for each_value in range(len(key_values)):\n",
        "        if each_value not in index_split:\n",
        "          modified_list.append(key_values[each_value])\n",
        "          value_list.append(key_values[each_value][1])\n",
        "      split_dict[ke]=modified_list\n",
        "    return split_dict, value_list\n",
        "\n",
        "  def create_decision_tree(self, dict_of_everything,class_val,eta_min_val):\n",
        "    global fea_list\n",
        "    if len(set(class_val)) ==1:\n",
        "      return Node(class_val[0],None,None,0,True)\n",
        "    elif len(class_val) < eta_min_val:\n",
        "      class_label = self.cal_major_class_values(class_val)\n",
        "      return Node(class_label,None,None,0,True)\n",
        "    else:\n",
        "      best_feature_list = self.best_feature(dict_of_everything)\n",
        "      node_name = best_feature_list[0]\n",
        "      theta = best_feature_list[1]\n",
        "      left_split = best_feature_list[2]\n",
        "      right_split = best_feature_list[3]\n",
        "      labels = best_feature_list[4]\n",
        "\n",
        "    left_split_dict, left_value_list= self.get_remainder_dict(dict_of_everything, left_split)\n",
        "    right_split_dict, right_value_list= self.get_remainder_dict(dict_of_everything, right_split)\n",
        "    left_split_node = self.create_decision_tree(left_split_dict,left_value_list,eta_min_val)\n",
        "    right_split_node = self.create_decision_tree(right_split_dict, right_value_list, eta_min_val)\n",
        "    root_node= Node(node_name, right_split_node, left_split_node, theta, False)\n",
        "    return root_node\n",
        "\n",
        "  def fit(self, dict_of_everything,cl_val,features,eta_min_val):\n",
        "      global fea_list\n",
        "      fea_list=features\n",
        "      self.root_node= self.create_decision_tree(dict_of_everything,cl_val,eta_min_val)\n",
        "\n",
        "      return self.root_node\n",
        "\n",
        "  def classify(self,row,root):\n",
        "    current_node = root\n",
        "    while not current_node.leaf:\n",
        "      if row[current_node.root_value]<current_node.theta:\n",
        "        current_node  = current_node.root_left\n",
        "      else:\n",
        "        current_node = current_node.root_right\n",
        "    return current_node.root_value\n",
        "\n",
        "  def predict(self, X, root):\n",
        "    prediction_list=[]\n",
        "    for i in X:\n",
        "      prediction_list.append(self.classify(i , root))\n",
        "    return prediction_list"
      ],
      "metadata": {
        "id": "YtiSGJWhN1es"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_for_predicted_values(test_class_names1,l):\n",
        "  true_count= 0\n",
        "  false_count = 0\n",
        "\n",
        "  for i in range(len(test_class_names1)):\n",
        "    if test_class_names1[i] == l[i]:\n",
        "      true_count += 1\n",
        "    else:\n",
        "      false_count += 1\n",
        "  \n",
        "  return true_count / (true_count + false_count)"
      ],
      "metadata": {
        "id": "HthJH-8DZVC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_dict_of_attributes_with_class_values(X,y):\n",
        "  attribute_dict = {}\n",
        "  feature_list = []\n",
        "\n",
        "  for i in range(X.shape[1]):\n",
        "    feature_index = i\n",
        "    values = X[:,i]\n",
        "    attribute_list = []\n",
        "    counter = 0\n",
        "    for value in values:\n",
        "      attribute_value = []\n",
        "      attribute_value.append(value)\n",
        "      attribute_value.append(y[counter])\n",
        "      attribute_list.append(attribute_value)\n",
        "      counter+=1\n",
        "    attribute_dict[feature_index] = attribute_list\n",
        "    feature_list.append(feature_index)\n",
        "  return attribute_dict,feature_list"
      ],
      "metadata": {
        "id": "OC0SNr0PythV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(num_arr, eta_min):\n",
        "  eta_min_val = round(eta_min*num_arr.shape[0])\n",
        "  num_arr = random_numpy_array(num_arr)\n",
        "\n",
        "  training_features,training_labels, testing_features, testing_labels = generate_set(num_arr)\n",
        "\n",
        "  cumulate_acc = 0\n",
        "\n",
        "  for i in range(10):\n",
        "    attribute_dict,feature_list = build_dict_of_attributes_with_class_values(training_features[i],training_labels[i])\n",
        "\n",
        "    DTree = DecisionTree()\n",
        "    DTree.fit(attribute_dict,training_labels[i],feature_list,eta_min_val)\n",
        "        \n",
        "    predicted_labels = DTree.predict(testing_features[i],DTree.root_node)\n",
        "\n",
        "    accu = accuracy_for_predicted_values(predicted_labels,testing_labels[i])\n",
        "    cumulate_acc+=accu\n",
        "    print(\"Accuracy is \",accu)\n",
        "  \n",
        "  print(\"Accuracy across 10-cross validation for\",eta_min,\"is\",float(cumulate_acc)/10)"
      ],
      "metadata": {
        "id": "r5HmuMyyZVoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eta_min_list = [0.05,0.10,0.15,0.20]\n",
        "newfile = \"iris.csv\"\n",
        "num_arr = load_csv(newfile)\n",
        "for i in eta_min_list:\n",
        "    main(num_arr,i)"
      ],
      "metadata": {
        "id": "bv4iP6OUJeBr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd108653-e91f-4015-fa76-4bbc3e5b1053"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy is  1.0\n",
            "Accuracy is  0.9333333333333333\n",
            "Accuracy is  0.8666666666666667\n",
            "Accuracy is  1.0\n",
            "Accuracy is  0.9333333333333333\n",
            "Accuracy is  1.0\n",
            "Accuracy is  0.9333333333333333\n",
            "Accuracy is  0.9333333333333333\n",
            "Accuracy is  1.0\n",
            "Accuracy is  0.9333333333333333\n",
            "Accuracy across 10-cross validation for 0.05 is 0.9533333333333335\n",
            "Standard Deviation:   0.04268749491621898\n",
            "Accuracy is  1.0\n",
            "Accuracy is  0.8666666666666667\n",
            "Accuracy is  1.0\n",
            "Accuracy is  1.0\n",
            "Accuracy is  0.8666666666666667\n",
            "Accuracy is  0.9333333333333333\n",
            "Accuracy is  0.9333333333333333\n",
            "Accuracy is  1.0\n",
            "Accuracy is  1.0\n",
            "Accuracy is  1.0\n",
            "Accuracy across 10-cross validation for 0.1 is 0.9600000000000002\n",
            "Standard Deviation:   0.05333333333333332\n",
            "Accuracy is  0.8666666666666667\n",
            "Accuracy is  1.0\n",
            "Accuracy is  1.0\n",
            "Accuracy is  1.0\n",
            "Accuracy is  1.0\n",
            "Accuracy is  0.9333333333333333\n",
            "Accuracy is  0.9333333333333333\n",
            "Accuracy is  1.0\n",
            "Accuracy is  0.9333333333333333\n",
            "Accuracy is  0.8\n",
            "Accuracy across 10-cross validation for 0.15 is 0.9466666666666669\n",
            "Standard Deviation:   0.06531972647421806\n",
            "Accuracy is  0.8\n",
            "Accuracy is  0.9333333333333333\n",
            "Accuracy is  1.0\n",
            "Accuracy is  0.8666666666666667\n",
            "Accuracy is  1.0\n",
            "Accuracy is  1.0\n",
            "Accuracy is  1.0\n",
            "Accuracy is  0.9333333333333333\n",
            "Accuracy is  1.0\n",
            "Accuracy is  1.0\n",
            "Accuracy across 10-cross validation for 0.2 is 0.9533333333333334\n",
            "Standard Deviation:   0.06699917080747259\n"
          ]
        }
      ]
    }
  ]
}